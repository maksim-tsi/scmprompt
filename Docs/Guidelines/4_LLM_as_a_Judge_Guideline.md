**Guideline: LLM-as-Judge for Evaluating Business Case Solving Outputs in SCM Logistics**

*   **Guideline Version:** 2.0
*   **Date:** 2024-07-16
*   **Purpose:** To provide a structured methodology for evaluating the **quality, coherence, relevance, and logical soundness** of the reasoning and proposed solutions generated by an LLM Assistant tasked with "Solving a Business Case" within the SCM Logistics domain, using a ground truth solution as a reference.
*   **Target Evaluator:** An LLM configured with these guidelines (or a human evaluator following them rigorously).

**Core Evaluation Principles (Inspired by McKinsey PST & Project Needs):**

*   **Objectivity & Rigor:** Evaluation should be based on demonstrable evidence within the provided inputs (scenario, assistant answer, ground truth).
*   **Scenario-Fact Verification:** Claims and reasoning steps in the assistant's answer should be checked for consistency with facts presented *only within the input `scenario_description`*.
*   **Multi-Faceted Assessment:** Evaluate the interpretation of the problem, the logical flow and structure of the reasoning, and the relevance and completeness of the proposed solution/analysis.
*   **Explanatory Feedback:** The evaluation should provide clear justifications for scores and identify specific strengths and weaknesses.
*   **Context Limitation:** Evaluation must be based *solely* on the provided `scenario_description`, `assistant_answer`, and `groundtruth_answer`, without recourse to external knowledge not present in these inputs.

**Required Inputs for the Judge:**

1.  **`scenario_description`:** The textual description of the business case/problem presented to the Assistant.
2.  **`assistant_answer`:** The full output generated by the LLM Assistant attempting to solve the case. This should ideally include both the reasoning process (e.g., Chain-of-Thought) and the final proposed analysis, recommendations, or solution.
3.  **`groundtruth_answer`:** The ideal or expert-derived solution and reasoning for the given `scenario_description`. This serves as the benchmark for quality and relevance (likely derived from the `expert_analysis_reasoning_steps` and potentially other elements of the original `scenario_datapoint`).

**Evaluation Steps & Criteria:**

The Judge should perform the following evaluations sequentially or in parallel:

**Step 1: Scenario Interpretation & Problem Understanding Assessment**

*   **Objective:** Assess if the Assistant correctly understood the core business problem, context, objectives, and constraints presented *in the `scenario_description`*. (Ref: PST Client Interpretation).
*   **Process:**
    1.  Read the initial parts of the `assistant_answer` (especially the reasoning/CoT trace).
    2.  Compare the Assistant's framing of the problem against the input `scenario_description`.
    3.  Evaluate: Does the Assistant accurately identify the central challenge? Does it acknowledge key stated facts, goals, or constraints? Or does its approach indicate a misunderstanding of the fundamental business issue described?
*   **Scoring:** Assign a qualitative rating (e.g., **High / Medium / Low**) or a numerical score (e.g., 1-5 scale) for **Interpretation Accuracy**. Provide justification, especially for Medium/Low scores (e.g., "Assistant focused on cost reduction, but the scenario's primary goal was market entry feasibility").

**Step 2: Reasoning Quality & Validity Assessment**

*   **Objective:** Evaluate the logical soundness, factual grounding (within the scenario), structure, and explanatory power of the Assistant's reasoning process (e.g., the CoT trace). This is a multi-part assessment.
*   **Process & Scoring (Score each sub-criterion, e.g., 1-5 scale or Pass/Minor Issue/Major Issue):**
    *   **2a. Factual Grounding (Scenario-Based):** (Ref: PST Reading Facts, Fact-based Conclusion - adapted)
        *   Does the reasoning accurately use specific facts, figures, or conditions *explicitly mentioned in the input `scenario_description`*?
        *   Does it avoid contradicting facts stated in the scenario?
        *   *Score/Flag:* Assess accuracy of scenario fact usage. Note specific errors (e.g., "Reasoning used a figure not present in the scenario description").
    *   **2b. Logical Soundness & Coherence:** (Ref: PST Fact-based Conclusion)
        *   Do the steps in the reasoning follow logically from one another and from the scenario facts?
        *   Are the inferences made plausible and internally consistent?
        *   Are there logical contradictions or significant unsupported leaps?
        *   *Score/Flag:* Assess overall logical coherence. Note specific logical flaws.
    *   **2c. Explanatory Quality & Causality:** (Ref: PST Root-cause Reason)
        *   Does the reasoning clearly explain *why* certain analyses are performed or *why* certain conclusions/recommendations are reached *based on the scenario*?
        *   Does it identify relevant drivers or factors contributing to the problem/solution described in the scenario?
        *   Is the causal link between analysis and conclusion clear and plausible?
        *   *Score/Flag:* Assess the quality of the explanation provided for key steps or conclusions.
    *   **2d. Structure & Clarity:** (Ref: PST Top Tips - Structured Approach)
        *   Is the reasoning presented in an organized manner (e.g., following a recognized framework like MECE, even if not explicitly named)?
        *   Is it easy to follow the Assistant's thought process? Is the language clear and unambiguous?
        *   *Score/Flag:* Assess the overall structure (e.g., hierarchical, logical flow) and readability.

**Step 3: Solution Relevance & Completeness Assessment**

*   **Objective:** Evaluate how well the Assistant's final proposed solution, analysis, or recommendations address the core business case presented in the `scenario_description`, compared to the `groundtruth_answer`.
*   **Process:**
    1.  Identify the core solution/analysis/recommendations presented in the `assistant_answer`.
    2.  Compare this against the key elements of the `groundtruth_answer`.
    3.  Evaluate:
        *   **Relevance:** Does the solution directly address the central question or problem of the business case?
        *   **Completeness:** Does the solution consider the major factors or aspects outlined as important in the `groundtruth_answer`? Are there significant omissions?
        *   **Actionability/Plausibility:** Is the proposed solution sensible and plausible within the context of the business scenario described? (Avoids clearly nonsensical suggestions).
*   **Scoring:** Assign a qualitative rating (e.g., **High / Medium / Low**) or a numerical score (e.g., 1-5 scale) for **Solution Quality**. Provide justification, highlighting alignment with or deviation from the ground truth, and noting any major omissions or irrelevant parts.

**Step 4: Synthesize Evaluation & Generate Report**

*   **Objective:** Combine the findings from Steps 1-3 into a comprehensive evaluation report.
*   **Process:**
    1.  **Aggregate Scores:** Compile the qualitative/numerical scores for Interpretation Accuracy, Reasoning Quality sub-criteria, and Solution Quality. Optionally calculate an overall score if a weighting scheme is defined.
    2.  **Generate Summary Feedback:** Write a concise overall summary (~1-3 sentences).
    3.  **Detail Strengths:** List specific aspects where the Assistant performed well (e.g., "Accurately identified the core profitability issue," "Reasoning followed a clear MECE structure," "Proposed solution considered key market factors").
    4.  **Detail Weaknesses/Errors:** List specific errors or areas for improvement, linking them back to the evaluation criteria. Be specific. (e.g., "Interpretation: Failed to note the stated budget constraint," "Reasoning Quality (Factual): Misstated market size mentioned in scenario," "Reasoning Quality (Logical): Conclusion did not follow from analysis," "Solution Quality: Omitted analysis of competitive response, which was key in ground truth").
*   **Output Format (Example):**
    ```json
    {
      "scenario_id": "SCM_CASE_MARKET_ENTRY_001", // Example
      "evaluation_summary": "Assistant correctly interpreted the market entry goal but failed to incorporate the competitive data provided in the scenario, leading to an incomplete analysis and solution.",
      "scores": {
        "interpretation_accuracy": "High", // Example
        "reasoning_factual_grounding": 2, // Example (Scale 1-5) - Failed to use competitive data
        "reasoning_logical_soundness": 4, // Example
        "reasoning_explanatory_quality": 3, // Example
        "reasoning_structure_clarity": 4, // Example
        "solution_quality": "Low" // Example - Due to incomplete analysis
        // "overall_weighted_score": 3.1 // Optional
      },
      "strengths": [
        "Clearly understood the objective of assessing market entry.",
        "Structured the analysis logically around market size, growth, and profitability."
      ],
      "weaknesses": [
        "Failed to incorporate competitive landscape details provided in the scenario description.",
        "Reasoning regarding potential profitability did not account for stated competitor strengths.",
        "Final recommendation lacked a competitive strategy component, unlike the ground truth solution."
      ]
    }
    ```

**Final Considerations:**

*   **Calibration:** Essential if using an LLM as the Judge. Use human-annotated examples reflecting different quality levels to fine-tune the Judge's scoring and feedback generation.
*   **Weighting:** Determine the relative importance of interpretation, reasoning facets, and solution quality for your specific evaluation goals.
*   **Ground Truth Quality:** The quality and comprehensiveness of the `groundtruth_answer` are critical for meaningful evaluation. It must represent a high standard of solving the business case.
*   **Iteration:** Refine these guidelines based on practical application and emerging evaluation needs.

**Synthesized LLM-as-a-Judge Prompt**
**Role:** You are an expert evaluator assessing the quality of responses generated by an AI Assistant tasked with solving a business case in SCM Logistics.

**Task:** Evaluate the provided `assistant_answer` based on the `scenario_description` and compare its reasoning against the `groundtruth_answer`. Focus your quantitative scoring on the quality of the Assistant's reasoning process.

**Core Principles:**
*   **Objectivity:** Base your evaluation solely on the provided texts.
*   **Scenario-Fact Adherence:** Verify reasoning against facts stated ONLY within the `scenario_description`. Do not use external knowledge.
*   **Context Limitation:** Your evaluation must be confined to the `scenario_description`, `assistant_answer`, and `groundtruth_answer`.

**Inputs:**
1.  `scenario_description`: {scenario_description}
2.  `assistant_answer`: {assistant_answer}
3.  `groundtruth_answer`: {groundtruth_answer}

**Evaluation Steps & Required Output:**

1.  **Analyze Interpretation:** Briefly assess if the Assistant understood the core problem in the `scenario_description`. (This informs context but is not directly scored in the final output).
2.  **Analyze Reasoning Quality:** Carefully examine the Assistant's reasoning steps (e.g., Chain-of-Thought). Evaluate the following aspects and provide a score from 1 (Poor) to 5 (Excellent) for each:
    *   **`reasoning_logical_soundness` (Score 1-5):** How logically coherent and internally consistent is the reasoning? Do steps follow plausibly from each other and the scenario facts (as interpreted by the assistant)? Are there major logical flaws or contradictions?
    *   **`reasoning_explanatory_quality` (Score 1-5):** How clearly and convincingly does the Assistant explain *why* it reaches certain conclusions or takes certain steps, based on the scenario? Is the causal link between analysis and conclusion clear?
    *   **`reasoning_structure_clarity` (Score 1-5):** How well-organized, structured, and easy to follow is the reasoning? Is the language clear?
3.  **Analyze Solution Relevance:** Briefly assess if the final solution/recommendation addresses the core issue in the `scenario_description` and aligns directionally with the `groundtruth_answer`. (This informs context but is not directly scored in the final output).
4.  **Generate Evaluation Report (JSON Format):** Output a JSON object containing:
    *   `evaluation_summary`: (String) A concise 1-2 sentence overall assessment of the assistant's performance, focusing on reasoning quality.
    *   `scores`: (Object) Containing the integer scores (1-5) for the three specific metrics:
        *   `reasoning_logical_soundness`: [Score 1-5]
        *   `reasoning_explanatory_quality`: [Score 1-5]
        *   `reasoning_structure_clarity`: [Score 1-5]
    *   `strengths`: (List of strings) Specific positive aspects observed, particularly regarding the scored reasoning criteria.
    *   `weaknesses`: (List of strings) Specific negative aspects or errors observed, particularly regarding the scored reasoning criteria, providing brief justification for lower scores.

**Example Output Structure:**
```json
{
  "evaluation_summary": "The assistant demonstrated moderately logical reasoning but lacked clarity in its explanations and structure.",
  "scores": {
    "reasoning_logical_soundness": 4,
    "reasoning_explanatory_quality": 3,
    "reasoning_structure_clarity": 2
  },
  "strengths": [
    "Followed a generally logical sequence from problem statement to conclusion.",
    "Correctly identified key variables from the scenario."
  ],
  "weaknesses": [
    "Explanations for intermediate conclusions were vague.",
    "The reasoning structure jumped between points, making it hard to follow.",
    "Did not clearly link the final recommendation back to specific reasoning steps."
  ]
}