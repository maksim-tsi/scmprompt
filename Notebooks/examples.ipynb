{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94857722",
   "metadata": {},
   "source": [
    "# Examples Notebook - SCM Logistics Case Examples\n",
    "\n",
    "This notebook demonstrates how to work with example cases and guidelines in the SCM logistics assistant system. It shows:\n",
    "\n",
    "1. Loading and exploring example case studies from the knowledge base\n",
    "2. Understanding the structure of example data\n",
    "3. Retrieving relevant examples for few-shot learning\n",
    "4. Using examples in prompt construction for the LLM assistant\n",
    "\n",
    "Examples are the foundation of the MedPrompt-inspired approach, providing the LLM with concrete patterns to follow when solving new logistics scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23739cbd",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Import necessary libraries and set up connections to the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee6d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Current working directory: /Users/max/Documents/code/scmprompt/Notebooks\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add the project root to the path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import utility functions\n",
    "from utils.qdrant_client import get_qdrant_client, get_embedding, search_datapoints, test_connection, COLLECTION_NAME\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74aca5f",
   "metadata": {},
   "source": [
    "## 2. Load Example Data\n",
    "\n",
    "Load example cases and guidelines from the project's data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3717a48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 245 generated case examples from ../Data/GeneratedCases/train_cases.parquet\n",
      "\n",
      "Dataset structure:\n",
      "Columns: ['case_id', 'title', 'enhanced_case', 'solution', 'file_path', 'enhanced_case_length', 'solution_length', 'realism_score', 'complexity_score', 'educational_value', 'solution_quality', 'overall_qualification', 'evaluation_summary', 'improvement_suggestions', 'case_for_embedding']\n",
      "Shape: (245, 15)\n",
      "\n",
      "Sample case structure (first example):\n",
      "  case_id: case-20250330-081720-dj177a\n",
      "  title: **Baltic Salmon Run: Navigating Regulatory Hurdles and Logistical Storms to Reach Asian Gourmet**\n",
      "  realism_score: 8.0\n",
      "  complexity_score: 7.0\n",
      "  educational_value: 9.0\n"
     ]
    }
   ],
   "source": [
    "# Load generated case examples from the training dataset\n",
    "generated_cases_file = Path(\"../Data/GeneratedCases/train_cases.parquet\")\n",
    "\n",
    "if generated_cases_file.exists():\n",
    "    # Load the parquet file with generated cases\n",
    "    examples_df = pd.read_parquet(generated_cases_file)\n",
    "    \n",
    "    print(f\"Loaded {len(examples_df)} generated case examples from {generated_cases_file}\")\n",
    "    \n",
    "    # Display structure of the dataset\n",
    "    print(\"\\nDataset structure:\")\n",
    "    print(f\"Columns: {list(examples_df.columns)}\")\n",
    "    print(f\"Shape: {examples_df.shape}\")\n",
    "    \n",
    "    # Show a sample of the data structure\n",
    "    if not examples_df.empty:\n",
    "        print(\"\\nSample case structure (first example):\")\n",
    "        first_case = examples_df.iloc[0]\n",
    "        for column in ['case_id', 'title', 'realism_score', 'complexity_score', 'educational_value']:\n",
    "            if column in first_case:\n",
    "                value = first_case[column]\n",
    "                if isinstance(value, str) and len(value) > 100:\n",
    "                    print(f\"  {column}: {value[:100]}...\")\n",
    "                else:\n",
    "                    print(f\"  {column}: {value}\")\n",
    "    \n",
    "    # Convert to list of dictionaries for easier processing\n",
    "    examples_data = examples_df.to_dict('records')\n",
    "else:\n",
    "    print(f\"Generated cases file not found at {generated_cases_file}\")\n",
    "    examples_data = []\n",
    "    examples_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2818940d",
   "metadata": {},
   "source": [
    "## 3. Explore Case Examples\n",
    "\n",
    "Examine the different types of case examples available in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91657364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "Total generated cases: 245\n",
      "Columns: ['case_id', 'title', 'enhanced_case', 'solution', 'file_path', 'enhanced_case_length', 'solution_length', 'realism_score', 'complexity_score', 'educational_value', 'solution_quality', 'overall_qualification', 'evaluation_summary', 'improvement_suggestions', 'case_for_embedding']\n",
      "\n",
      "Case Quality Metrics:\n",
      "  realism_score: mean=8.1, std=0.3\n",
      "  complexity_score: mean=7.1, std=0.3\n",
      "  educational_value: mean=8.7, std=0.5\n",
      "  solution_quality: mean=7.7, std=0.4\n",
      "\n",
      "Qualification status:\n",
      "overall_qualification\n",
      "QUALIFIED    243\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Case length statistics:\n",
      "  Enhanced case length: mean=7004, std=1200\n",
      "  Solution length: mean=59525, std=60537\n",
      "\n",
      "================================================================================\n",
      "SAMPLE GENERATED CASE:\n",
      "================================================================================\n",
      "\n",
      "CASE ID: case-20250330-081720-dj177a\n",
      "TITLE: **Baltic Salmon Run: Navigating Regulatory Hurdles and Logistical Storms to Reach Asian Gourmet**\n",
      "QUALITY SCORES: Realism=8.0, Complexity=7.0, Educational=9.0\n",
      "\n",
      "CASE PREVIEW:\n",
      "**Scenario:** Baltic Breeze Seafood, a rapidly expanding seafood processor in Riga, Latvia, has secured a lucrative contract to supply frozen salmon fillets to a major supermarket chain, \"Asian Gourmet,\" with distribution centers throughout Japan. The contract stipulates specific delivery windows and penalties for late shipments, making reliable and timely logistics paramount. **Key Entities:** * Baltic Breeze Seafood (shipper, located in Riga, Latvia) * North Star Shipping (carrier, operating a fleet of container vessels between Northern Europe and Asia) * Asian Gourmet (customer of Baltic Breeze, supermarket chain in Japan) * Riga Cold Storage (third-party logistics provider offering refrigerated warehousing and container stuffing services in Riga) * \"Icebreaker\" (North Star Shipping's d...\n",
      "\n",
      "SOLUTION PREVIEW:\n",
      "## Executive Summary Baltic Breeze Seafood faces a complex logistical challenge in delivering frozen salmon fillets to Asian Gourmet in Japan, complicated by regulatory requirements, operational hurdles, and an unexpected weather delay. This solution addresses these challenges through proactive planning, enhanced monitoring, and contingency measures. The core strategy focuses on mitigating risks related to reefer container availability, port congestion, temperature control, customs clearance, an...\n"
     ]
    }
   ],
   "source": [
    "if not examples_df.empty:\n",
    "    print(\"Dataset Overview:\")\n",
    "    print(f\"Total generated cases: {len(examples_df)}\")\n",
    "    print(f\"Columns: {list(examples_df.columns)}\")\n",
    "    \n",
    "    # Analyze case quality metrics\n",
    "    print(\"\\nCase Quality Metrics:\")\n",
    "    for metric in ['realism_score', 'complexity_score', 'educational_value', 'solution_quality']:\n",
    "        if metric in examples_df.columns:\n",
    "            print(f\"  {metric}: mean={examples_df[metric].mean():.1f}, std={examples_df[metric].std():.1f}\")\n",
    "    \n",
    "    # Analyze qualification status\n",
    "    if 'overall_qualification' in examples_df.columns:\n",
    "        print(\"\\nQualification status:\")\n",
    "        print(examples_df['overall_qualification'].value_counts())\n",
    "    \n",
    "    # Show case length statistics\n",
    "    if 'enhanced_case_length' in examples_df.columns:\n",
    "        print(f\"\\nCase length statistics:\")\n",
    "        print(f\"  Enhanced case length: mean={examples_df['enhanced_case_length'].mean():.0f}, std={examples_df['enhanced_case_length'].std():.0f}\")\n",
    "    \n",
    "    if 'solution_length' in examples_df.columns:\n",
    "        print(f\"  Solution length: mean={examples_df['solution_length'].mean():.0f}, std={examples_df['solution_length'].std():.0f}\")\n",
    "    \n",
    "    # Show a sample case\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SAMPLE GENERATED CASE:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Find a well-qualified case for demonstration\n",
    "    qualified_cases = examples_df[examples_df['overall_qualification'] == 'QUALIFIED'] if 'overall_qualification' in examples_df.columns else examples_df\n",
    "    if not qualified_cases.empty:\n",
    "        sample_case = qualified_cases.iloc[0]\n",
    "    else:\n",
    "        sample_case = examples_df.iloc[0]\n",
    "    \n",
    "    print(f\"\\nCASE ID: {sample_case.get('case_id', 'N/A')}\")\n",
    "    print(f\"TITLE: {sample_case.get('title', 'N/A')}\")\n",
    "    \n",
    "    if 'realism_score' in sample_case:\n",
    "        print(f\"QUALITY SCORES: Realism={sample_case['realism_score']}, Complexity={sample_case['complexity_score']}, Educational={sample_case['educational_value']}\")\n",
    "    \n",
    "    # Show case content preview\n",
    "    case_content = sample_case.get('enhanced_case', sample_case.get('case_for_embedding', ''))\n",
    "    if case_content:\n",
    "        print(f\"\\nCASE PREVIEW:\")\n",
    "        preview = case_content[:800] + \"...\" if len(case_content) > 800 else case_content\n",
    "        print(preview)\n",
    "    \n",
    "    # Show solution preview\n",
    "    solution_content = sample_case.get('solution', '')\n",
    "    if solution_content:\n",
    "        print(f\"\\nSOLUTION PREVIEW:\")\n",
    "        solution_preview = solution_content[:500] + \"...\" if len(solution_content) > 500 else solution_content\n",
    "        print(solution_preview)\n",
    "else:\n",
    "    print(\"No generated case examples available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbe7a19",
   "metadata": {},
   "source": [
    "## 3.1. Export Sample Case to Text File\n",
    "\n",
    "Export the full details of the sample case to a text file for detailed review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9fe8a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Case exported successfully!\n",
      "  File: /Users/max/Documents/code/scmprompt/Data/GeneratedCases/txt/case-20250330-081720-dj177a.txt\n",
      "  Case ID: case-20250330-081720-dj177a\n",
      "  Title: **Baltic Salmon Run: Navigating Regulatory Hurdles and Logistical Storms to Reach Asian Gourmet**\n",
      "  File size: 24286 bytes\n",
      "\n",
      "File preview (first 500 characters):\n",
      "------------------------------------------------------------\n",
      "================================================================================\n",
      "MARITIME LOGISTICS CASE STUDY\n",
      "================================================================================\n",
      "\n",
      "Case ID: case-20250330-081720-dj177a\n",
      "Title: **Baltic Salmon Run: Navigating Regulatory Hurdles and Logistical Storms to Reach Asian Gourmet**\n",
      "Exported: 2025-07-19 11:04:12\n",
      "\n",
      "QUALITY METRICS:\n",
      "----------------------------------------\n",
      "Realism Score: 8.0\n",
      "Complexity Score: 7.0\n",
      "Educational Value: 9.0\n",
      "Solution Qua\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def safe_get_value(series, key, default=''):\n",
    "    \"\"\"Safely extract a value from pandas Series, handling numpy arrays and NaN values.\"\"\"\n",
    "    try:\n",
    "        value = series.get(key, default)\n",
    "        if pd.isna(value) or value is None:\n",
    "            return default\n",
    "        if isinstance(value, np.ndarray):\n",
    "            return str(value)\n",
    "        return str(value)\n",
    "    except:\n",
    "        return default\n",
    "\n",
    "# Export the sample case to a text file\n",
    "if not examples_df.empty and 'sample_case' in locals():\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = Path(\"/Users/max/Documents/code/scmprompt/Data/GeneratedCases/txt\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get case details safely\n",
    "    case_id = safe_get_value(sample_case, 'case_id', 'unknown')\n",
    "    title = safe_get_value(sample_case, 'title', 'Untitled Case')\n",
    "    \n",
    "    # Use only case ID for filename (simplified as requested)\n",
    "    filename = f\"{case_id}.txt\"\n",
    "    filepath = output_dir / filename\n",
    "    \n",
    "    # Prepare the content\n",
    "    content_lines = []\n",
    "    content_lines.append(\"=\" * 80)\n",
    "    content_lines.append(\"MARITIME LOGISTICS CASE STUDY\")\n",
    "    content_lines.append(\"=\" * 80)\n",
    "    content_lines.append(\"\")\n",
    "    content_lines.append(f\"Case ID: {case_id}\")\n",
    "    content_lines.append(f\"Title: {title}\")\n",
    "    content_lines.append(f\"Exported: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    content_lines.append(\"\")\n",
    "    \n",
    "    # Add quality scores if available\n",
    "    realism_score = safe_get_value(sample_case, 'realism_score')\n",
    "    if realism_score and realism_score != '':\n",
    "        content_lines.append(\"QUALITY METRICS:\")\n",
    "        content_lines.append(\"-\" * 40)\n",
    "        content_lines.append(f\"Realism Score: {safe_get_value(sample_case, 'realism_score')}\")\n",
    "        content_lines.append(f\"Complexity Score: {safe_get_value(sample_case, 'complexity_score')}\")\n",
    "        content_lines.append(f\"Educational Value: {safe_get_value(sample_case, 'educational_value')}\")\n",
    "        content_lines.append(f\"Solution Quality: {safe_get_value(sample_case, 'solution_quality', 'N/A')}\")\n",
    "        content_lines.append(f\"Overall Qualification: {safe_get_value(sample_case, 'overall_qualification', 'N/A')}\")\n",
    "        content_lines.append(\"\")\n",
    "    \n",
    "    # Add case content\n",
    "    case_content = safe_get_value(sample_case, 'enhanced_case')\n",
    "    if not case_content:\n",
    "        case_content = safe_get_value(sample_case, 'case_for_embedding')\n",
    "    \n",
    "    if case_content and case_content.strip():\n",
    "        content_lines.append(\"CASE SCENARIO:\")\n",
    "        content_lines.append(\"=\" * 80)\n",
    "        content_lines.append(\"\")\n",
    "        content_lines.append(case_content)\n",
    "        content_lines.append(\"\")\n",
    "    \n",
    "    # Add solution\n",
    "    solution_content = safe_get_value(sample_case, 'solution')\n",
    "    if solution_content and solution_content.strip():\n",
    "        content_lines.append(\"SOLUTION:\")\n",
    "        content_lines.append(\"=\" * 80)\n",
    "        content_lines.append(\"\")\n",
    "        content_lines.append(solution_content)\n",
    "        content_lines.append(\"\")\n",
    "    \n",
    "    # Add additional metadata if available\n",
    "    evaluation_summary = safe_get_value(sample_case, 'evaluation_summary')\n",
    "    if evaluation_summary and evaluation_summary.strip():\n",
    "        content_lines.append(\"EVALUATION SUMMARY:\")\n",
    "        content_lines.append(\"-\" * 40)\n",
    "        content_lines.append(evaluation_summary)\n",
    "        content_lines.append(\"\")\n",
    "    \n",
    "    improvement_suggestions = safe_get_value(sample_case, 'improvement_suggestions')\n",
    "    if improvement_suggestions and improvement_suggestions.strip():\n",
    "        content_lines.append(\"IMPROVEMENT SUGGESTIONS:\")\n",
    "        content_lines.append(\"-\" * 40)\n",
    "        content_lines.append(improvement_suggestions)\n",
    "        content_lines.append(\"\")\n",
    "    \n",
    "    # Write to file\n",
    "    try:\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(content_lines))\n",
    "        \n",
    "        print(f\"✓ Case exported successfully!\")\n",
    "        print(f\"  File: {filepath}\")\n",
    "        print(f\"  Case ID: {case_id}\")\n",
    "        print(f\"  Title: {title}\")\n",
    "        print(f\"  File size: {filepath.stat().st_size} bytes\")\n",
    "        \n",
    "        # Show file preview\n",
    "        print(f\"\\nFile preview (first 500 characters):\")\n",
    "        print(\"-\" * 60)\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            preview_content = f.read(500)\n",
    "            print(preview_content)\n",
    "            if len(preview_content) == 500:\n",
    "                print(\"...\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error writing file: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"No sample case available to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c96901",
   "metadata": {},
   "source": [
    "## 4. Connect to Vector Database\n",
    "\n",
    "Test connection to Qdrant and explore the stored examples collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da66516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Qdrant connection\n",
    "try:\n",
    "    print(\"Testing Qdrant connection...\")\n",
    "    test_connection()\n",
    "    \n",
    "    # Get client\n",
    "    client = get_qdrant_client()\n",
    "    \n",
    "    # Get collection info\n",
    "    try:\n",
    "        collection_info = client.get_collection(COLLECTION_NAME)\n",
    "        print(f\"\\nCollection '{COLLECTION_NAME}' info:\")\n",
    "        print(f\"  Points count: {collection_info.points_count}\")\n",
    "        print(f\"  Vector size: {collection_info.config.params.vectors.size}\")\n",
    "        print(f\"  Distance metric: {collection_info.config.params.vectors.distance}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not get collection info: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Qdrant connection failed: {e}\")\n",
    "    print(\"You can still explore the examples data without vector search.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ae10f",
   "metadata": {},
   "source": [
    "## 5. Search for Relevant Examples\n",
    "\n",
    "Demonstrate how to search for examples relevant to a specific scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201dacb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example search query\n",
    "sample_scenario = \"Container shipping from Hamburg to Singapore with dangerous goods\"\n",
    "\n",
    "print(f\"Searching for examples relevant to: '{sample_scenario}'\")\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "try:\n",
    "    # Search using the vector database\n",
    "    results = search_datapoints(\n",
    "        query=sample_scenario,\n",
    "        limit=3,\n",
    "        content_type_filter=\"example\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(results)} relevant examples:\")\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. Example (Score: {result.score:.3f})\")\n",
    "        print(f\"   ID: {result.payload.get('chunk_id', 'N/A')}\")\n",
    "        print(f\"   Type: {result.payload.get('example_type', 'N/A')}\")\n",
    "        \n",
    "        # Show content preview\n",
    "        content = result.payload.get('content', '')\n",
    "        if content:\n",
    "            preview = content[:200] + \"...\" if len(content) > 200 else content\n",
    "            print(f\"   Preview: {preview}\")\n",
    "        \n",
    "        # Show summary if available\n",
    "        summary = result.payload.get('summary', '')\n",
    "        if summary:\n",
    "            summary_preview = summary[:150] + \"...\" if len(summary) > 150 else summary\n",
    "            print(f\"   Summary: {summary_preview}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Vector search failed: {e}\")\n",
    "    print(\"\\nFalling back to simple text search in loaded generated cases...\")\n",
    "    \n",
    "    # Simple fallback search using generated cases\n",
    "    if not examples_df.empty:\n",
    "        search_terms = sample_scenario.lower().split()\n",
    "        relevant_cases = []\n",
    "        \n",
    "        for idx, row in examples_df.iterrows():\n",
    "            # Search in case content and title\n",
    "            case_text = str(row.get('enhanced_case', row.get('case_for_embedding', ''))).lower()\n",
    "            title_text = str(row.get('title', '')).lower()\n",
    "            \n",
    "            # Simple keyword matching\n",
    "            matches = sum(1 for term in search_terms if term in case_text or term in title_text)\n",
    "            if matches > 0:\n",
    "                relevant_cases.append((row, matches))\n",
    "        \n",
    "        # Sort by number of matches\n",
    "        relevant_cases.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"Found {len(relevant_cases)} potentially relevant cases:\")\n",
    "        for i, (case, matches) in enumerate(relevant_cases[:3], 1):\n",
    "            print(f\"\\n{i}. {case.get('title', 'Untitled Case')} (Matches: {matches})\")\n",
    "            print(f\"   Case ID: {case.get('case_id', 'N/A')}\")\n",
    "            if 'realism_score' in case:\n",
    "                print(f\"   Quality: Realism={case['realism_score']}, Complexity={case['complexity_score']}\")\n",
    "            \n",
    "            case_content = case.get('enhanced_case', case.get('case_for_embedding', ''))\n",
    "            if case_content:\n",
    "                content_preview = case_content[:300] + \"...\" if len(case_content) > 300 else case_content\n",
    "                print(f\"   Preview: {content_preview}\")\n",
    "    else:\n",
    "        print(\"No generated cases available for search.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47368a15",
   "metadata": {},
   "source": [
    "## 6. Example Usage in Prompt Construction\n",
    "\n",
    "Show how retrieved examples can be used to construct few-shot prompts for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e651764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_case_for_prompt(case_data):\n",
    "    \"\"\"\n",
    "    Format a generated case for use in a few-shot prompt.\n",
    "    \"\"\"\n",
    "    formatted = \"EXAMPLE CASE:\\n\"\n",
    "    formatted += \"=\" * 50 + \"\\n\"\n",
    "    \n",
    "    # Add case title and ID\n",
    "    title = case_data.get('title', 'Untitled Case')\n",
    "    case_id = case_data.get('case_id', 'N/A')\n",
    "    formatted += f\"Title: {title}\\n\"\n",
    "    formatted += f\"Case ID: {case_id}\\n\\n\"\n",
    "    \n",
    "    # Add case scenario\n",
    "    case_content = case_data.get('enhanced_case', case_data.get('case_for_embedding', ''))\n",
    "    if case_content:\n",
    "        # Limit case content for prompt size\n",
    "        if len(case_content) > 1000:\n",
    "            case_content = case_content[:1000] + \"...\"\n",
    "        formatted += f\"Scenario:\\n{case_content}\\n\\n\"\n",
    "    \n",
    "    # Add solution\n",
    "    solution = case_data.get('solution', '')\n",
    "    if solution:\n",
    "        # Limit solution for prompt size  \n",
    "        if len(solution) > 800:\n",
    "            solution = solution[:800] + \"...\"\n",
    "        formatted += f\"Solution:\\n{solution}\\n\\n\"\n",
    "    \n",
    "    # Add quality metrics if available\n",
    "    if 'realism_score' in case_data:\n",
    "        formatted += f\"Quality Metrics: Realism={case_data['realism_score']}, \"\n",
    "        formatted += f\"Complexity={case_data['complexity_score']}, \"\n",
    "        formatted += f\"Educational Value={case_data['educational_value']}\\n\\n\"\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "# Demonstrate prompt construction with generated cases\n",
    "print(\"EXAMPLE OF FEW-SHOT PROMPT CONSTRUCTION WITH GENERATED CASES:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if not examples_df.empty:\n",
    "    # Use a qualified case for demonstration\n",
    "    demo_case = None\n",
    "    if 'overall_qualification' in examples_df.columns:\n",
    "        qualified_cases = examples_df[examples_df['overall_qualification'] == 'QUALIFIED']\n",
    "        if not qualified_cases.empty:\n",
    "            demo_case = qualified_cases.iloc[0]\n",
    "    \n",
    "    if demo_case is None:\n",
    "        demo_case = examples_df.iloc[0]\n",
    "    \n",
    "    example_prompt = format_case_for_prompt(demo_case)\n",
    "    \n",
    "    # Construct a sample few-shot prompt\n",
    "    few_shot_prompt = f\"\"\"\n",
    "You are an expert in maritime logistics and supply chain management. \n",
    "Based on the following example cases, analyze new scenarios and provide structured solutions.\n",
    "\n",
    "{example_prompt}\n",
    "\n",
    "Now analyze this new scenario:\n",
    "Scenario: {sample_scenario}\n",
    "\n",
    "Provide a structured analysis following the pattern shown in the example above.\n",
    "\"\"\"\n",
    "    \n",
    "    print(few_shot_prompt)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Note: In practice, you would use 2-3 most relevant cases retrieved from the vector database.\")\n",
    "else:\n",
    "    print(\"No generated cases available for prompt construction demonstration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2485c54",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "This notebook demonstrated the basic workflow for working with examples in the SCM logistics assistant system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ed6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EXAMPLES NOTEBOOK SUMMARY:\")\n",
    "print(\"=\" * 40)\n",
    "print(\"✓ Loaded generated case examples from train_cases.parquet\")\n",
    "print(\"✓ Explored the structure and quality metrics of generated cases\")\n",
    "print(\"✓ Demonstrated vector-based similarity search\")\n",
    "print(\"✓ Showed how to construct few-shot prompts with real cases\")\n",
    "print()\n",
    "print(\"Available data:\")\n",
    "if not examples_df.empty:\n",
    "    print(f\"  - {len(examples_df)} total generated cases\")\n",
    "    if 'overall_qualification' in examples_df.columns:\n",
    "        qualified_count = len(examples_df[examples_df['overall_qualification'] == 'QUALIFIED'])\n",
    "        print(f\"  - {qualified_count} qualified cases ready for use\")\n",
    "    print(f\"  - Quality scores available for evaluation\")\n",
    "else:\n",
    "    print(\"  - No cases loaded (check file path)\")\n",
    "    \n",
    "print()\n",
    "print(\"Next steps:\")\n",
    "print(\"  1. Use vector search to find relevant cases for specific scenarios\")\n",
    "print(\"  2. Construct few-shot prompts with 2-3 most relevant cases\")\n",
    "print(\"  3. Apply the MedPrompt approach for improved LLM performance\")\n",
    "print(\"\\nNEXT STEPS:\")\n",
    "print(\"- Try different search queries to find relevant examples\")\n",
    "print(\"- Experiment with prompt construction using multiple examples\")\n",
    "print(\"- Use examples in the main case generation pipeline (04_Case_Generation.ipynb)\")\n",
    "print(\"- Evaluate example relevance and quality for your specific use cases\")\n",
    "print(\"\\nRELATED NOTEBOOKS:\")\n",
    "print(\"- 02_Test_Queries.ipynb: Advanced search and retrieval\")\n",
    "print(\"- 03_Embed_Examples_Guidelines.ipynb: Creating and updating example embeddings\")\n",
    "print(\"- 04_Case_Generation.ipynb: Using examples in case generation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
